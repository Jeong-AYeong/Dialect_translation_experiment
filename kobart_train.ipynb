{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3985e6a6-b5f6-4c54-bbc7-8e8c2bc94387",
   "metadata": {},
   "source": [
    "# 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "848a892f-05d2-4a08-b10c-c0131cfcfda3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_form</th>\n",
       "      <th>dialect_form</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그러고 디스플레이 부족하댄허난하다고 하니까 사람을 구해준 것 아닙니까</td>\n",
       "      <td>겅허고 디스플레이 부족하댄허난하다고 하니까 사람을 구해준 것 아니꽈</td>\n",
       "      <td>0.855086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>너 종합병원이야 갑자기 다리꼬지마</td>\n",
       "      <td>너 종합병원 갑자기 다리꼬지마</td>\n",
       "      <td>0.835181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그러니까 요즘에 오는 관광객들</td>\n",
       "      <td>게난 요즘에 오는 관광객들</td>\n",
       "      <td>0.734492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그렇게 하니까 한번 해볼까 해서 그냥 호기심으로 했지</td>\n",
       "      <td>경 하니까 한번 해보카 해연에 그냥 호기심으로 했주게</td>\n",
       "      <td>0.725456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>오들락오들락 잘 나 정말 곱게 난다 잡초 하나 없이</td>\n",
       "      <td>오들락오들락 잘 나메 정말 곱게 난다 검질 호나 어시</td>\n",
       "      <td>0.880031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            standard_form  \\\n",
       "0  그러고 디스플레이 부족하댄허난하다고 하니까 사람을 구해준 것 아닙니까   \n",
       "1                      너 종합병원이야 갑자기 다리꼬지마   \n",
       "2                        그러니까 요즘에 오는 관광객들   \n",
       "3           그렇게 하니까 한번 해볼까 해서 그냥 호기심으로 했지   \n",
       "4            오들락오들락 잘 나 정말 곱게 난다 잡초 하나 없이   \n",
       "\n",
       "                            dialect_form  similarity  \n",
       "0  겅허고 디스플레이 부족하댄허난하다고 하니까 사람을 구해준 것 아니꽈    0.855086  \n",
       "1                       너 종합병원 갑자기 다리꼬지마    0.835181  \n",
       "2                         게난 요즘에 오는 관광객들    0.734492  \n",
       "3          경 하니까 한번 해보카 해연에 그냥 호기심으로 했주게    0.725456  \n",
       "4          오들락오들락 잘 나메 정말 곱게 난다 검질 호나 어시    0.880031  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"jeju_train_similarity.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb84b7f0-e45c-4320-a7b6-2df1ef2bb294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 893111 entries, 0 to 893110\n",
      "Data columns (total 3 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   standard_form  893107 non-null  object \n",
      " 1   dialect_form   893110 non-null  object \n",
      " 2   similarity     893111 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 20.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b4e3b9d-3b45-4645-8d18-9578ec4716be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standard_form    4\n",
       "dialect_form     1\n",
       "similarity       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4df1d3-b132-4d29-9409-47370a6cd964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>standard_form</th>\n",
       "      <th>dialect_form</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그러고 디스플레이 부족하댄허난하다고 하니까 사람을 구해준 것 아닙니까</td>\n",
       "      <td>겅허고 디스플레이 부족하댄허난하다고 하니까 사람을 구해준 것 아니꽈</td>\n",
       "      <td>0.855086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>너 종합병원이야 갑자기 다리꼬지마</td>\n",
       "      <td>너 종합병원 갑자기 다리꼬지마</td>\n",
       "      <td>0.835181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그러니까 요즘에 오는 관광객들</td>\n",
       "      <td>게난 요즘에 오는 관광객들</td>\n",
       "      <td>0.734492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그렇게 하니까 한번 해볼까 해서 그냥 호기심으로 했지</td>\n",
       "      <td>경 하니까 한번 해보카 해연에 그냥 호기심으로 했주게</td>\n",
       "      <td>0.725456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>오들락오들락 잘 나 정말 곱게 난다 잡초 하나 없이</td>\n",
       "      <td>오들락오들락 잘 나메 정말 곱게 난다 검질 호나 어시</td>\n",
       "      <td>0.880031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            standard_form  \\\n",
       "0  그러고 디스플레이 부족하댄허난하다고 하니까 사람을 구해준 것 아닙니까   \n",
       "1                      너 종합병원이야 갑자기 다리꼬지마   \n",
       "2                        그러니까 요즘에 오는 관광객들   \n",
       "3           그렇게 하니까 한번 해볼까 해서 그냥 호기심으로 했지   \n",
       "4            오들락오들락 잘 나 정말 곱게 난다 잡초 하나 없이   \n",
       "\n",
       "                            dialect_form  similarity  \n",
       "0  겅허고 디스플레이 부족하댄허난하다고 하니까 사람을 구해준 것 아니꽈    0.855086  \n",
       "1                       너 종합병원 갑자기 다리꼬지마    0.835181  \n",
       "2                         게난 요즘에 오는 관광객들    0.734492  \n",
       "3          경 하니까 한번 해보카 해연에 그냥 호기심으로 했주게    0.725456  \n",
       "4          오들락오들락 잘 나메 정말 곱게 난다 검질 호나 어시    0.880031  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6819ba-5b46-4664-b2c8-31155df6e325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\anaconda3\\envs\\koreanNLP\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "from tokenizers import Tokenizer, normalizers\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from datasets import Dataset\n",
    "from transformers import PreTrainedTokenizerFast, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "660ea482-4d2a-4903-980a-5901a4525aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, BertTokenizer, AutoTokenizer\n",
    "# Define custom tokenizer class\n",
    "class CustomSPTokenizer(PreTrainedTokenizerFast):\n",
    "    def __init__(self, tokenizer_path):\n",
    "        super().__init__(tokenizer_file=tokenizer_path)\n",
    "        self._tokenizer = Tokenizer.from_file(tokenizer_path)\n",
    "\n",
    "    def _tokenize(self, text):\n",
    "        return self._tokenizer.encode(text).tokens\n",
    "\n",
    "    def _convert_token_to_id(self, token):\n",
    "        return self._tokenizer.token_to_id(token)\n",
    "\n",
    "    def _convert_id_to_token(self, index):\n",
    "        return self._tokenizer.id_to_token(index)\n",
    "\n",
    "    def convert_tokens_to_string(self, tokens):\n",
    "        return self._tokenizer.decode(tokens)\n",
    "\n",
    "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
    "        if token_ids_1 is None:\n",
    "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
    "        cls = [self.cls_token_id]\n",
    "        sep = [self.sep_token_id]\n",
    "        return cls + token_ids_0 + sep + token_ids_1 + sep + [self.sep_token_id]\n",
    "\n",
    "    @property\n",
    "    def cls_token_id(self):\n",
    "        return self._tokenizer.token_to_id(\"<cls>\")\n",
    "\n",
    "    @property\n",
    "    def sep_token_id(self):\n",
    "        return self._tokenizer.token_to_id(\"<sep>\")\n",
    "\n",
    "    @property\n",
    "    def pad_token_id(self):\n",
    "        return self._tokenizer.token_to_id(\"<pad>\")\n",
    "\n",
    "    @property\n",
    "    def unk_token_id(self):\n",
    "        return self._tokenizer.token_to_id(\"<unk>\")\n",
    "\n",
    "# Initialize the custom tokenizer\n",
    "tokenizer_path = \"bpe_tokenizer.json\"\n",
    "custom_tokenizer = CustomSPTokenizer(tokenizer_path)\n",
    "custom_tokenizer.add_special_tokens({'pad_token': '<pad>'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d6d0f3-5fc6-4867-8ce7-fd7f32cb8ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\koreanNLP\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "You passed along `num_labels=3` with an incompatible id to label map: {'0': 'NEGATIVE', '1': 'POSITIVE'}. The number of labels wil be overwritten to 2.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"gogamza/kobart-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c10f89e7-f155-4af7-a6f6-e1a3165433d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(16000, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(custom_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56f252a7-a195-44ef-801e-6cc0dbd216b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343461ea02494fbabd4b0eac5484a4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/714484 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\koreanNLP\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3921: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a72a07e19a493fbb0b62a45c800e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/178622 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset의 column :  ['input_ids', 'attention_mask', 'labels']\n",
      "val_dataset의 column :  ['input_ids', 'attention_mask', 'labels']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex for ex in examples['standard_form']]\n",
    "    targets = [ex for ex in examples['dialect_form']]\n",
    "    # inputs = [ex for ex in examples['dialect_form']]\n",
    "    # targets = [ex for ex in examples['standard_form']]\n",
    "    model_inputs = custom_tokenizer(inputs, max_length=100, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with custom_tokenizer.as_target_tokenizer():\n",
    "        labels = custom_tokenizer(targets, max_length=100, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)   \n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "train_dataset = train_dataset.map(preprocess_function,batched=True)\n",
    "\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "val_dataset = val_dataset.map(preprocess_function,batched=True)\n",
    "\n",
    "# Filter out unwanted columns\n",
    "train_dataset = train_dataset.remove_columns(['standard_form', 'dialect_form', '__index_level_0__', 'token_type_ids','similarity'])\n",
    "val_dataset = val_dataset.remove_columns(['standard_form', 'dialect_form', '__index_level_0__', 'token_type_ids','similarity'])\n",
    "print(\"train_dataset의 column : \",train_dataset.column_names)\n",
    "print(\"val_dataset의 column : \",val_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe916ee-69f5-4bda-8598-66211b7bae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52fac53-b52c-49d9-b31b-bc549b0c2cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BART model\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(\"gogamza/kobart-base-v2\")\n",
    "model.to(device)\n",
    "\n",
    "# 로그 디렉토리 경로 설정\n",
    "log_dir = r\"C:\\Users\\user\\Desktop\\logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",  # 'epoch' 대신 'steps'로 설정하여 주기적으로 평가\n",
    "    eval_steps=500,  # 평가 주기를 500 스텝으로 설정 BART는 5000주기\n",
    "    save_steps=1000,  # 체크포인트 저장 주기를 1000 스텝으로 설정\n",
    "    learning_rate=2e-5,  # 일반적으로 2e-5와 같은 낮은 학습률이 안정적\n",
    "    per_device_train_batch_size=32,  # GPU 메모리와 성능에 따라 조정  Bart = 16. KoBART = 32\n",
    "    per_device_eval_batch_size=32,  # 평가 시에도 배치 크기를 맞춤  Bart = 16. KoBART = 32\n",
    "    num_train_epochs=3,  # 기본 에포크 수\n",
    "    weight_decay=0.01,  # 가중치 감쇠\n",
    "    logging_dir=log_dir,  # 로그 디렉토리\n",
    "    logging_steps=100,  # 로그 주기를 100 스텝으로 설정  Bart = 500. KoBART = 100\n",
    "    save_total_limit=2,  # 저장할 체크포인트 수 제한\n",
    "    load_best_model_at_end=True,  # 학습이 끝난 후 가장 좋은 모델을 로드\n",
    "    gradient_accumulation_steps=2,  # 그래디언트 누적을 통해 배치 크기 증가 효과\n",
    ")\n",
    "\n",
    "\n",
    "# Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=custom_tokenizer,\n",
    "    eval_dataset=val_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3203b0-2be2-479d-a678-33178dd97cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\envs\\koreanNLP\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:587: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23501' max='33492' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [23501/33492 7:31:22 < 3:11:54, 0.87 it/s, Epoch 2.10/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.260400</td>\n",
       "      <td>0.233933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.198892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.176541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.164800</td>\n",
       "      <td>0.160974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.149700</td>\n",
       "      <td>0.152923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.144607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.140200</td>\n",
       "      <td>0.136957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.135700</td>\n",
       "      <td>0.131497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.130100</td>\n",
       "      <td>0.127183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.128300</td>\n",
       "      <td>0.122712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.119198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.116310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.115900</td>\n",
       "      <td>0.112884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.112500</td>\n",
       "      <td>0.111316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.108986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.109400</td>\n",
       "      <td>0.107374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.104252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.106400</td>\n",
       "      <td>0.103010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.102322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.103000</td>\n",
       "      <td>0.099751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.101300</td>\n",
       "      <td>0.097837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.099800</td>\n",
       "      <td>0.096317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>0.094941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.093703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.093575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.095300</td>\n",
       "      <td>0.092663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.092677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.091125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.090100</td>\n",
       "      <td>0.090947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.090081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.089215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.088040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.087462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.086624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.088700</td>\n",
       "      <td>0.086650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.087400</td>\n",
       "      <td>0.086074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.086002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.086500</td>\n",
       "      <td>0.085835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.085310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.085100</td>\n",
       "      <td>0.084729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.085800</td>\n",
       "      <td>0.084174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>0.083912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.083414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.082848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.082882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.082650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1738' max='5582' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1738/5582 01:59 < 04:24, 14.52 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(\"./kobart_train\")\n",
    "# model.save_pretrained(\"./translated_model_bart100_sort_dialect_to_standard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb41b16b-08fd-4e27-b744-0b79522869d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "C:\\Users\\user\\anaconda3\\envs\\koreanNLP\\lib\\site-packages\\transformers\\models\\bart\\modeling_bart.py:587: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33492' max='33492' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33492/33492 3:17:50, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.081900</td>\n",
       "      <td>0.082444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>0.081749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.081902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.081596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.081022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.081346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.081147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.080592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.080414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.080360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.079879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.080005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.080031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.079817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.079491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.079663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.077500</td>\n",
       "      <td>0.079728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.079501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.081000</td>\n",
       "      <td>0.079432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.079600</td>\n",
       "      <td>0.079473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n",
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.decoder.embed_tokens.weight', 'lm_head.weight'].\n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'forced_eos_token_id': 1}\n"
     ]
    }
   ],
   "source": [
    "# 학습 시작 또는 재개\n",
    "trainer.train(resume_from_checkpoint=r'C:\\Users\\user\\Desktop\\jeju\\results\\checkpoint-23000')\n",
    "\n",
    "# 모델 저장\n",
    "model.save_pretrained(\"./kobart_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e247efe7-0685-4f67-b06c-29446f8f5682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
